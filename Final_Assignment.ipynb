{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MTvVyzgYP5t"
      },
      "source": [
        "#Final Assignment\n",
        "ntroduction where you discuss the business problem and who would be interested in this project.\n",
        "\n",
        "Data where you describe the data that will be used to solve the problem and the source of the data.\n",
        "\n",
        "Methodology section which represents the main component of the report where you discuss and describe any exploratory data analysis that you did, any inferential statistical testing that you performed, if any, and what machine learnings were used and why.\n",
        "\n",
        "Results section where you discuss the results.\n",
        "\n",
        "Discussion section where you discuss any observations you noted and any recommendations you can make based on the results.\n",
        "\n",
        "Conclusion section where you conclude the report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd3ryTArUODX",
        "outputId": "f32e9f22-125e-4b22-e4f0-a2c4145d562c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import requests\n",
        "import time\n",
        "%pip install geocoder\n",
        "import geocoder"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting geocoder\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/6b/13166c909ad2f2d76b929a4227c952630ebaf0d729f6317eb09cbceccbab/geocoder-1.38.1-py2.py3-none-any.whl (98kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from geocoder) (7.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from geocoder) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from geocoder) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from geocoder) (1.15.0)\n",
            "Collecting ratelim\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/98/7e6d147fd16a10a5f821db6e25f192265d6ecca3d82957a4fdd592cad49c/ratelim-0.1.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->geocoder) (2020.6.20)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ratelim->geocoder) (4.4.2)\n",
            "Installing collected packages: ratelim, geocoder\n",
            "Successfully installed geocoder-1.38.1 ratelim-0.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWGkkp4xEF52",
        "outputId": "f1cdacdc-c1a7-426a-baa3-00e763bdc5e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "df = pd.read_csv('population by town-city.csv')\n",
        "df['Size'] = \"\"\n",
        "df.head\n",
        " \n",
        "for index, row in df.iterrows():\n",
        "  df.iloc[index, 0] = df.iloc[index, 0].replace(\"buadisp2011:\", \"\")\n",
        "  df.iloc[index, 0] = df.iloc[index, 0].replace(\" BUASD\", \"\")\n",
        "  df.iloc[index, 0] = df.iloc[index, 0].replace(\" BUA\", \"\")\n",
        "  string = df.iloc[index, 0]\n",
        "  i = 0\n",
        "  i = string.find(\" - \")\n",
        "  if i != -1:\n",
        "    df.iloc[index, 0] = string[i+3:]\n",
        " \n",
        "df.head"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                  Area   mnemonic    2011    2012  ...    2017    2018    2019  Size\n",
              "0               Kexby  E34000001     342     342  ...     364     352     337      \n",
              "1     Bradfield Heath  E34000002     724     715  ...     821     838     831      \n",
              "2             Huntley  E34000003    1108    1121  ...    1127    1108    1131      \n",
              "3          Swinefleet  E34000004     787     758  ...     787     794     770      \n",
              "4            Foulsham  E34000005    1021     995  ...    1017     987     965      \n",
              "...               ...        ...     ...     ...  ...     ...     ...     ...   ...\n",
              "6616       Pontardawe  W38000146   12349   12357  ...   12801   12970   13096      \n",
              "6617          Newport  W38000147  128115  128855  ...  133353  134920  136078      \n",
              "6618       Bryn Pydew  W38000149     448     477  ...     454     448     449      \n",
              "6619      Pentre Berw  W38000150     392     397  ...     404     421     416      \n",
              "6620      Mynydd-bach  W38000153     391     366  ...     392     412     386      \n",
              "\n",
              "[6621 rows x 12 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjzclbuEj5Sf"
      },
      "source": [
        "# create a list of our conditions\n",
        "conditions = [(df['2019'] >= 7500) & (df['2019'] <= 24999),\n",
        "    (df['2019'] >= 25000) & (df['2019'] <= 59999)\n",
        "    ]\n",
        "\n",
        "# create a list of the values we want to assign for each condition\n",
        "values = ['Small Town', 'Medium Town']\n",
        "\n",
        "# create a new column and use np.select to assign values to it using our lists as arguments\n",
        "df['Size'] = np.select(conditions, values)\n",
        "\n",
        "\n",
        "size_df = df[df['Size'] != \"0\"]\n",
        "size_df.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAk8bob0lpQI",
        "outputId": "edf9bf47-1dd8-4b6c-c74f-f524419ee5c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        }
      },
      "source": [
        "size_df['Latitude'] = \"\"\n",
        "size_df['Longitude'] = \"\"\n",
        " \n",
        " \n",
        "for index, row in size_df.iterrows():\n",
        "  latlong = None\n",
        "  while latlong == None:\n",
        "    g = geocoder.arcgis('{}, United Kingdom'.format(row['Area']))\n",
        "    latlong = g.latlng\n",
        "  lat = str(latlong[0])\n",
        "  long = str(latlong[1])\n",
        "  size_df.iloc[index, 13] = long[:10]\n",
        "  size_df.iloc[index, 12] = lat[:9]\n",
        " \n",
        "size_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1765: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>mnemonic</th>\n",
              "      <th>2011</th>\n",
              "      <th>2012</th>\n",
              "      <th>2013</th>\n",
              "      <th>2014</th>\n",
              "      <th>2015</th>\n",
              "      <th>2016</th>\n",
              "      <th>2017</th>\n",
              "      <th>2018</th>\n",
              "      <th>2019</th>\n",
              "      <th>Size</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dorchester (West Dorset)</td>\n",
              "      <td>E34000016</td>\n",
              "      <td>19031</td>\n",
              "      <td>19152</td>\n",
              "      <td>19521</td>\n",
              "      <td>19633</td>\n",
              "      <td>19750</td>\n",
              "      <td>20254</td>\n",
              "      <td>20633</td>\n",
              "      <td>21082</td>\n",
              "      <td>21438</td>\n",
              "      <td>Small Town</td>\n",
              "      <td>50.710920</td>\n",
              "      <td>-2.4423399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ely</td>\n",
              "      <td>E34000020</td>\n",
              "      <td>19270</td>\n",
              "      <td>19591</td>\n",
              "      <td>19543</td>\n",
              "      <td>19948</td>\n",
              "      <td>20053</td>\n",
              "      <td>20144</td>\n",
              "      <td>20255</td>\n",
              "      <td>20321</td>\n",
              "      <td>20330</td>\n",
              "      <td>Small Town</td>\n",
              "      <td>52.401370</td>\n",
              "      <td>0.26370000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Downham Market</td>\n",
              "      <td>E34000027</td>\n",
              "      <td>10882</td>\n",
              "      <td>10974</td>\n",
              "      <td>11192</td>\n",
              "      <td>11349</td>\n",
              "      <td>11650</td>\n",
              "      <td>11841</td>\n",
              "      <td>11937</td>\n",
              "      <td>11871</td>\n",
              "      <td>11910</td>\n",
              "      <td>Small Town</td>\n",
              "      <td>52.602360</td>\n",
              "      <td>0.37877000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Penrith</td>\n",
              "      <td>E34000039</td>\n",
              "      <td>15172</td>\n",
              "      <td>15232</td>\n",
              "      <td>15267</td>\n",
              "      <td>15287</td>\n",
              "      <td>15324</td>\n",
              "      <td>15376</td>\n",
              "      <td>15494</td>\n",
              "      <td>15542</td>\n",
              "      <td>15880</td>\n",
              "      <td>Small Town</td>\n",
              "      <td>54.664750</td>\n",
              "      <td>-2.7569299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bolsover</td>\n",
              "      <td>E34000048</td>\n",
              "      <td>11767</td>\n",
              "      <td>12002</td>\n",
              "      <td>12042</td>\n",
              "      <td>12104</td>\n",
              "      <td>12052</td>\n",
              "      <td>12019</td>\n",
              "      <td>12014</td>\n",
              "      <td>11984</td>\n",
              "      <td>11996</td>\n",
              "      <td>Small Town</td>\n",
              "      <td>53.229250</td>\n",
              "      <td>-1.2907199</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Area   mnemonic  ...   Latitude   Longitude\n",
              "0  Dorchester (West Dorset)  E34000016  ...  50.710920  -2.4423399\n",
              "1                       Ely  E34000020  ...  52.401370  0.26370000\n",
              "2            Downham Market  E34000027  ...  52.602360  0.37877000\n",
              "3                   Penrith  E34000039  ...  54.664750  -2.7569299\n",
              "4                  Bolsover  E34000048  ...  53.229250  -1.2907199\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv6xzDHR93Ch"
      },
      "source": [
        "CLIENT_ID = '31FBQ4JXECZV0OKLQFEDFTWIKMA0CCKDTNJ3JFCMTQLNQHT3' # your Foursquare ID\n",
        "CLIENT_SECRET = 'UHA3UUT4XUGCX5ABTQSH41WXLGNQUISCE35RFSFCG1HHP5LG' # your Foursquare Secret\n",
        "VERSION = '20180605' # Foursquare API version\n",
        "LIMIT = 100\n",
        "radius = 5000\n",
        "categoryId= '52f2ab2ebcbc57f1066b8b46'\n",
        " \n",
        "# create URL\n",
        "def create_url(lat, long):\n",
        "  url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{},&radius={}&limit={}&categoryId={}'.format(\n",
        "      CLIENT_ID, \n",
        "      CLIENT_SECRET, \n",
        "      VERSION, \n",
        "      lat,\n",
        "      long,\n",
        "      radius, \n",
        "      LIMIT,\n",
        "      categoryId)\n",
        "  return url\n",
        " \n",
        " \n",
        "res_df = pd.DataFrame(columns=['Area', 'Venue Category', 'Venue Name', 'Longitude', 'Latitude'])\n",
        "temp_df = res_df\n",
        "temp_df.at[1, :] = \"\"\n",
        "for index, row in size_df.iterrows():\n",
        "  temp = temp_df\n",
        "  lat = row['Latitude']\n",
        "  long = row['Longitude']\n",
        "  url = create_url(lat, long)\n",
        "  try:\n",
        "    results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
        "    time.sleep(1)\n",
        "    for res in results:\n",
        "      temp['Area'] = row['Area']\n",
        "      temp['Venue Name'] = res['venue']['name']\n",
        "      temp['Venue Category'] = res['venue']['categories'][0]['name']\n",
        "      temp['Longitude'] = res['venue']['location']['labeledLatLngs'][0]['lng']\n",
        "      temp['Latitude'] = res['venue']['location']['labeledLatLngs'][0]['lat']\n",
        "      res_df = res_df.append(temp, ignore_index=True)\n",
        "  except:\n",
        "    print(\"Skipping {}\".format(index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rBkg_xcSzk2"
      },
      "source": [
        "res_df = res_df[res_df['Venue Category'] == 'Supermarket']\n",
        "res_df.to_csv('results.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-GM0_Y62lAT",
        "outputId": "1a3e5d65-c58c-4f94-c1a3-f20505fb10d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(res_df.shape)\n",
        "res_df.drop_duplicates(inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4780, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUycBuoE_SC8",
        "outputId": "8100582b-0f48-4cfb-f69f-3794815b8c57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "res_df = pd.read_csv('results.csv')\n",
        "print(\"Initial amount of unique names: {}\".format(len(res_df['Venue Name'].unique().tolist())))\n",
        "\n",
        "clean_df = res_df\n",
        "search_name = ['orriso','o-op', 'press', 'aitrose', 'ermark', 'Tesco Superstore', 'Warehouse']\n",
        "new_name = ['Morrisons', 'Co-op', 'Tesco Express', 'Waitrose & Partners', 'Generic Supermarket', 'Tesco Extra', 'Iceland']\n",
        "\n",
        "for index, row in clean_df.iterrows():\n",
        "  for num, name in enumerate(search_name):\n",
        "    if name in row['Venue Name']:\n",
        "      clean_df.loc[index, 'Venue Name'] = new_name[num]\n",
        "\n",
        "print(\"Post Cleaning amount of unique names: {}\".format(len(res_df['Venue Name'].unique().tolist())))\n",
        "\n",
        "a = clean_df['Venue Name'].value_counts()\n",
        "drop_list = []\n",
        "for num, count in enumerate(a):\n",
        "  if count < 10:\n",
        "    drop_list.append(a.index[num])\n",
        "\n",
        "#create drop series and specify types to keep\n",
        "drop_index = []\n",
        "\n",
        "#remove unwanted data\n",
        "print(\"Removing unwanted Data\")\n",
        "for index, row in clean_df.iterrows():\n",
        "  if row['Venue Name'] in drop_list:\n",
        "    drop_index.append(index)\n",
        "\n",
        "#clear unwanted data from 05 system type            \n",
        "clean_df.drop(index = drop_index, axis =1, inplace=True)\n",
        "clean_df.reset_index()\n",
        "\n",
        "\n",
        "print(\"Post Cleaning low count names: {}\".format(len(res_df['Venue Name'].unique().tolist())))\n",
        "\n",
        "print(clean_df['Venue Name'].unique().tolist())\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial amount of unique names: 106\n",
            "Post Cleaning amount of unique names: 51\n",
            "Removing unwanted Data\n",
            "Post Cleaning low count names: 15\n",
            "['Waitrose & Partners', 'Lidl', 'Tesco', \"Sainsbury's\", 'Aldi', 'Morrisons', 'Booths', 'Tesco Extra', 'Asda', \"Sainsbury's Local\", 'Iceland', 'Co-op', 'Tesco Express', 'Generic Supermarket', 'Nisa Local']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pFal_IW4jBn"
      },
      "source": [
        "clean_df.to_csv('clean.csv')"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL1YpeVZksNU"
      },
      "source": [
        " num_top_venues = 10\n",
        " \n",
        "for hood in manhattan_grouped['Neighborhood']:\n",
        "    print(\"----\"+hood+\"----\")\n",
        "    temp = manhattan_grouped[manhattan_grouped['Neighborhood'] == hood].T.reset_index()\n",
        "    temp.columns = ['venue','freq']\n",
        "    temp = temp.iloc[1:]\n",
        "    temp['freq'] = temp['freq'].astype(float)\n",
        "    temp = temp.round({'freq': 2})\n",
        "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylUhm3mkgm_N"
      },
      "source": [
        "# New section"
      ]
    }
  ]
}